{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "from celverapi.core import *\n",
    "import pandas as pd\n",
    "import concurrent.futures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "# ---- Loading DataFrame\n",
    "\n",
    "df = pd.read_parquet('C:/Users/kevinkeipert/Desktop/Data/example.parquet')\n",
    "\n",
    "# ---- Project Variables \n",
    "\n",
    "id_column = \"store_nbr\"         #Name of the Column where the Product IDs are located.\n",
    "                                #This will split the DataFrame into smaller DataFrames from every single unique value in the column.\n",
    "\n",
    "date_column = \"date\"               #Name of the Colum where the Date is located. \n",
    "\n",
    "date_to_split = \"2017-08-01\"    #YYYY-MM-DD from where we want to split the DataFrames into Training and Test sets. \n",
    "                                #In this example, the Train set will be every day until 2017-08-01. And the Test set from 2017-08-01 (inclusive), until the end of the DataFrame.\n",
    "\n",
    "value_column = \"sales\"             #Name of the Column where the values to messure are located. \n",
    "                                #In this example is the sales Column that contains the amount of money per day. \n",
    "\n",
    "forecast_horizon = 15           #Amount of steps to forecast "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "\n",
    "def unique_dataframe_values(id_column: str):\n",
    "    \n",
    "    \"\"\"\n",
    "    This Function returns a List of DataFrames from every unique Value in the ID Column.\n",
    "\n",
    "    -   id_column (String) : Name of the Column from the DataFrame where the Unique IDs are located. This will split the DataFrame into smaller DataFrames from every single unique value in the column.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    list_of_df = []\n",
    "\n",
    "    array_uvalues = df[id_column].unique()\n",
    "\n",
    "    for value in array_uvalues: \n",
    "\n",
    "        df_value = df[df[id_column] == value]\n",
    "        list_of_df.append(df_value)\n",
    "\n",
    "    return list_of_df \n",
    "\n",
    "list_of_df = unique_dataframe_values(id_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def split_into_train_test_dataframe(list_of_df: list, date_column: str, date_to_split: str):\n",
    "\n",
    "    \"\"\"\n",
    "    The function splits the DataFrames into a Traing and Test sets.\n",
    "    The DataFrames are saved in 2 Differents Lists, one for TRAIN DF and other for TEST DF.\n",
    "    It returs two lists: list_of_trained_df, list_of_test_df\n",
    "\n",
    "    -   list_of_df (List) : Lists of DataFrames with only one ID.\n",
    "    -   date_column (String) : Name of the Colum where the Date is located.\n",
    "    -   date_to_split (String) : YYYY-MM-DD from where we want to split the DataFrames into Training and Test sets. Example, the Train set will be every day until 2017-08-01. And the Test set from 2017-08-01 (inclusive), until the end of the DataFrame.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    list_df_train = []\n",
    "    list_df_val = []\n",
    "    \n",
    "    for df in list_of_df:\n",
    "    \n",
    "        df_train = df[df[date_column] < date_to_split]\n",
    "        df_val = df[df[date_column] >= date_to_split]\n",
    "\n",
    "        list_df_train.append(df_train)\n",
    "        list_df_val.append(df_val)\n",
    "\n",
    "    return list_df_train, list_df_val\n",
    "\n",
    "list_df_train, list_df_val = split_into_train_test_dataframe(list_of_df, date_column, date_to_split)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def converting_dataframes_into_objects(list_df_train: list, list_df_val: list, date_column: str, id_column: str, value_column: str):\n",
    "\n",
    "    \"\"\"\n",
    "    The function creates TimeSeries Object from the respective DataFrames\n",
    "    The Objects are saved in 2 Differents Lists, one for TRAIN DF and other for TEST DF.\n",
    "    It returs two lists: trained_timeseries, valed_timeseries\n",
    "\n",
    "    -   list_df_train : List of trained DataFrames\n",
    "    -   list_df_val (List) : List of tested DataFrames \n",
    "    -   date_column (String) : Name of the Colum where the Date is located.\n",
    "    -   id_column (String) : Name of the Column from the DataFrame where the Unique IDs are located.\n",
    "    -   value_column (String) : Name of the Column where the values to messure are located. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    trained_ts = []\n",
    "    valed_ts = []\n",
    "\n",
    "    for df in list_df_train:\n",
    "\n",
    "        ts_train = TimeSeries(df, date_column, id_column, value_column)\n",
    "        trained_ts.append(ts_train)\n",
    "\n",
    "    for df in list_df_val:\n",
    "\n",
    "        ts_val = TimeSeries(df, date_column, id_column, value_column)\n",
    "        valed_ts.append(ts_val)\n",
    "\n",
    "\n",
    "    return trained_ts, valed_ts\n",
    "\n",
    "trained_ts, valed_ts= converting_dataframes_into_objects(list_df_train, list_df_val, date_column, id_column, value_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def creating_forecasting_task_dict(trained_ts: list, valed_ts: list, forecast_horizon: int):\n",
    "\n",
    "    \"\"\"\n",
    "    The function creates a dictionary mapping the ID value with the respective ForecastingTask object. \n",
    "    It returs a dictionary : dict_of_forecasting_tasks \n",
    "\n",
    "    -   trained_ts (List) : List of trained Timeseries objects. \n",
    "    -   valed_ts (List) : List of tested/validated objects. \n",
    "    -   forecast_horizon (int) : Amount of steps to forecast \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    dict_of_forecasting_tasks = {} \n",
    "\n",
    "    for i in range(len(trained_ts)):\n",
    "\n",
    "        ft = ForecastingTask(train=trained_ts[i], out_of_sample=None, validation=valed_ts[i], forecast_horizon= forecast_horizon)\n",
    "        dict_of_forecasting_tasks[trained_ts[i].get_id()] = ft\n",
    "\n",
    "    return dict_of_forecasting_tasks\n",
    "\n",
    "\n",
    "dict_of_forecasting_tasks = creating_forecasting_task_dict(trained_ts, valed_ts, forecast_horizon=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "\n",
    "\n",
    "def ets_func(ft: ForecastingTask):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function for the ETS Model. \n",
    "    It returns a DataFrame with the following columns: Qty(Predicted), ID, Date, Model\n",
    "\n",
    "    - ft : ForecastingTask Object \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    ets = ETSModel(ft)\n",
    "    ets.fit()\n",
    "    prediction = ets.predict()\n",
    "    id = ft.train.get_id()\n",
    "    datum = ft.validation.get_datum()\n",
    "\n",
    "    final_dataframe = prediction.to_frame(name='Qty')\n",
    "    final_dataframe['ID'] = id \n",
    "    final_dataframe['Date'] = datum\n",
    "    final_dataframe['Model'] = 'ETS-Model'\n",
    "    \n",
    "    return final_dataframe\n",
    "\n",
    "def naive_func(ft: ForecastingTask):\n",
    "\n",
    "    \"\"\"\n",
    "    Function for the Naive Model. \n",
    "    It returns a DataFrame with the following columns: Qty(Predicted), ID, Date, Model\n",
    "\n",
    "    - ft : ForecastingTask Object \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    naive = NaiveForecast(ft)\n",
    "    naive.fit()\n",
    "    prediction = naive.predict()\n",
    "    id = ft.train.get_id()\n",
    "    datum = ft.validation.get_datum()\n",
    "\n",
    "    final_dataframe = prediction.to_frame(name='Qty')\n",
    "    final_dataframe['ID'] = id \n",
    "    final_dataframe['Date'] = datum\n",
    "    final_dataframe['Model'] = 'Naive Model'\n",
    "    \n",
    "    return final_dataframe\n",
    "\n",
    "def trend_func(ft: ForecastingTask):\n",
    "\n",
    "    \"\"\"\n",
    "    Function for the Trend Model. \n",
    "    It returns a DataFrame with the following columns: Qty(Predicted), ID, Date, Model\n",
    "\n",
    "    - ft : ForecastingTask Object \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    theta = TrendForecast(ft)\n",
    "    theta.fit()\n",
    "    prediction = theta.predict()\n",
    "    id = ft.train.get_id()\n",
    "    datum = ft.validation.get_datum()\n",
    "\n",
    "    final_dataframe = prediction.to_frame(name='Qty')\n",
    "    final_dataframe['ID'] = id \n",
    "    final_dataframe['Date'] = datum\n",
    "    final_dataframe['Model'] = 'Trend Model'\n",
    "    \n",
    "    return final_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def forecast(list_of_models: list, dict_of_forecasting_tasks: dict):\n",
    "\n",
    "    \"\"\"\n",
    "    This Function allows the user to forecast multiple Timeseires and multiple Models simultaneously using a multiprocessing aproach. \n",
    "    It returns a DataFrame with all the models and Timeseries passed in the function.\n",
    "\n",
    "    -   list_of_models(List) : A list with the Forecasting models to apply. For the moment only \"ets\", \"naive\" and trend\".\n",
    "    -   dict_of_forecasting_tasks(Dict) : A dictionary with the Forecasting tasks. Can be created with the function \"creating_forecasting_task_dict()\". \n",
    "\n",
    "    > Important: This function needs to run inside of the if __name__ == '__main__' condition.  \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor: \n",
    "\n",
    "        # List with all the Forecasted Objects \n",
    "        final_results_ets = []\n",
    "        final_results_naive = []\n",
    "        final_results_trend = []\n",
    "\n",
    "\n",
    "        final_df = []\n",
    "\n",
    "        # Run, for example various TimeSeries simultainly for Arima Model \n",
    "\n",
    "        if \"ets\" in list_of_models:\n",
    "\n",
    "            ets_prediction = executor.map(ets_func, dict_of_forecasting_tasks.values())\n",
    "\n",
    "            for result in ets_prediction:\n",
    "                final_results_ets.append(result)\n",
    "            \n",
    "            result_ets = pd.concat(final_results_ets)\n",
    "            final_df.append(result_ets)\n",
    "\n",
    "        if \"naive\" in list_of_models:\n",
    "            \n",
    "            naive_prediction = executor.map(naive_func, dict_of_forecasting_tasks.values())\n",
    "\n",
    "            for result in naive_prediction:\n",
    "                final_results_naive.append(result) \n",
    "\n",
    "            result_naive = pd.concat(final_results_naive)\n",
    "            final_df.append(result_naive)\n",
    "\n",
    "        if \"trend\" in list_of_models:\n",
    "\n",
    "            theta_prediction = executor.map(trend_func, dict_of_forecasting_tasks.values())\n",
    "\n",
    "            for result in theta_prediction:\n",
    "                final_results_trend.append(result)\n",
    "        \n",
    "            result_trend = pd.concat(final_results_trend)\n",
    "            final_df.append(result_trend)\n",
    "\n",
    "        result = pd.concat(final_df)\n",
    "\n",
    "\n",
    "    return result\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
